# RTGS AI Analyst â€” Real-Time Government Statistics AI Pipeline

**ğŸ¯ A multi-agent AI system that transforms messy government datasets into actionable policy insights in minutes, not months.**

[![Demo Video](https://img.shields.io/badge/ğŸ“¹_Demo_Video-Watch_Now-red)](YOUR_DEMO_VIDEO_LINK)
[![LangSmith Traces](https://img.shields.io/badge/ğŸ”_LangSmith-View_Traces-blue)](YOUR_LANGSMITH_LINK)
[![Report Sample](https://img.shields.io/badge/ğŸ“Š_Sample_Report-View_PDF-green)](artifacts/reports/sample/report.pdf)

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone https://github.com/your-org/rtgs-ai-analyst
cd rtgs-ai-analyst
pip install -r requirements.txt

# Run analysis on any government dataset
python main.py run \
  --source "data/vehicle_registrations_hyderabad_2023.csv" \
  --domain-hint transport \
  --scope "district=Hyderabad,year=2023" \
  --auto-approve

# âœ… Get instant executive summary + full report in artifacts/
```

**ğŸ’¡ What you get:** Clean data + Interactive charts + Policy recommendations + Full audit trail â€” all generated automatically.

---

## ğŸ¯ Problem We Solve

Government data analysts spend **80% of their time** cleaning data and only **20% analyzing**. RTGS AI Analyst flips this ratio:

**Before RTGS:**
- 3-4 weeks to clean a messy district dataset
- Manual schema mapping and outlier detection  
- Copy-paste analysis in Excel
- Static reports that become outdated

**After RTGS:**
- **3-4 minutes** end-to-end automated pipeline
- AI-powered schema inference and standardization
- Statistical analysis with hypothesis testing
- Interactive reports with confidence scores

---

## ğŸ—ï¸ System Architecture

RTGS uses a **multi-agent architecture** orchestrated by LangGraph, with each agent handling a specific data transformation step:

```
Raw Dataset â†’ [11 AI Agents] â†’ Policy-Ready Insights

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 LangGraph Orchestrator                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Agent Flow (Linear Chain)                      â”‚   â”‚
â”‚   â”‚                                                 â”‚   â”‚
â”‚   â”‚  Ingest â†’ Schema â†’ Standard â†’ Clean â†’ Transform â”‚   â”‚
â”‚   â”‚     â†“        â†“        â†“        â†“        â†“       â”‚   â”‚
â”‚   â”‚  Validate â†’ Analyze â†’ Insights â†’ Report â†’ Memory â”‚   â”‚
â”‚   â”‚                                                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”           â”Œâ”€â”€â”€â–¼â”€â”€â”€â”           â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
    â”‚LangChainâ”‚          â”‚LlamaIndexâ”‚        â”‚Observabilityâ”‚
    â”‚(Tools)  â”‚          â”‚(Memory)  â”‚        â”‚(LangSmith)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Framework Roles

- **ğŸ­ LangGraph**: Orchestrates the multi-agent pipeline, handles retries, branching logic
- **ğŸ”§ LangChain**: Powers individual agent tools (cleaning chains, analysis tools, report generation)  
- **ğŸ§  LlamaIndex**: Long-term memory for schema mappings, transform decisions, and semantic Q&A
- **ğŸ‘ï¸ LangSmith**: Observability and tracing for debugging and audit trails

---

## ğŸ¤– The 11 AI Agents

### **Data Processing Agents**

#### 1. ğŸ“¥ **Ingestion Agent**
- **Role**: Fetches and validates raw data sources
- **Input**: URLs, file paths, domain hints
- **Output**: Raw data copy + basic manifest + sample rows
- **Smart Features**:
  - Auto-detects CSV/Excel encoding and separators
  - Handles multi-sheet Excel files
  - Streams large files (>100MB) efficiently
  - Generates dataset fingerprint for caching

#### 2. ğŸ” **Schema Inference Agent** 
- **Role**: Understands what each column contains
- **Input**: Sample data rows + domain context
- **Output**: Inferred types + canonical names + confidence scores
- **Smart Features**:
  - Detects 8 data types: numeric, datetime, categorical, boolean, geo, ID, text
  - AI-powered column naming (e.g., "veh_reg_dt" â†’ "vehicle_registration_date")
  - Confidence scoring for ambiguous columns
  - Domain-aware type detection (transport, health, education)

#### 3. ğŸ—ï¸ **Standardization Agent**
- **Role**: Makes column names and formats consistent
- **Input**: Raw data + inferred schema
- **Output**: Standardized dataset with canonical column names
- **Smart Features**:
  - Snake_case column naming
  - Unit detection and normalization  
  - Boolean standardization (Yes/No â†’ True/False)
  - Reusable alias mapping across datasets

#### 4. ğŸ§¹ **Cleaning Agent**
- **Role**: Handles missing data, duplicates, and outliers
- **Input**: Standardized data + cleaning policies
- **Output**: Clean dataset + detailed transform log
- **Smart Features**:
  - **Missing Data**: Median impute (<5% missing), group impute (<20%), drop column (>95%)
  - **Duplicates**: Exact + fuzzy duplicate detection
  - **Outliers**: IQR-based flagging with configurable thresholds
  - **Human-in-loop**: Requires approval for high-impact transforms (>5% rows affected)

#### 5. âš¡ **Transformation Agent**
- **Role**: Creates analysis-ready features
- **Input**: Clean data + domain knowledge
- **Output**: Transformed dataset with derived features
- **Smart Features**:
  - **Time Features**: Year/month extraction, rolling averages, percent change
  - **Per-Capita Metrics**: Population-normalized KPIs for geographic analysis
  - **Statistical Features**: Quantile buckets, correlation-ready variables
  - **Domain Templates**: Transport (vehicle density), Health (per-1000 rates), Education (dropout rates)

### **Analysis & Intelligence Agents**

#### 6. âœ… **Validator Agent**
- **Role**: Quality assurance and confidence scoring
- **Input**: Transformed data + transform history
- **Output**: Validation report + quality gates + confidence score (HIGH/MEDIUM/LOW)
- **Quality Gates**:
  - Completeness checks on key columns
  - Data type consistency validation
  - Range plausibility checks
  - Transform impact assessment

#### 7. ğŸ“Š **Analysis Agent**  
- **Role**: Computes statistical insights and KPIs
- **Input**: Clean dataset + KPI definitions
- **Output**: Numerical analysis + charts metadata + hypothesis tests
- **Statistical Methods**:
  - **KPIs**: Sum, mean, median, std, min, max, count for all numeric fields
  - **Time Trends**: Linear trend fitting + seasonality detection via autocorrelation
  - **Spatial Analysis**: Geographic inequality using Gini coefficient + per-capita rankings
  - **Hypothesis Testing**: T-tests and Wilcoxon tests with effect size (Cohen's d)
  - **Correlation Analysis**: Spearman correlation matrix with significance testing

#### 8. ğŸ’¡ **Insight Generation Agent** (LLM-Powered)
- **Role**: Converts numbers into policy-relevant narratives  
- **Input**: Statistical outputs + domain context
- **Output**: Executive summary + prioritized recommendations + confidence badges
- **AI Features**:
  - Plain-language impact statements ("Vehicle registrations up 6% in Hyderabad")
  - Evidence-backed recommendations with statistical justification
  - Priority ranking by impact and confidence
  - **Privacy-Safe**: Only aggregated stats sent to LLM, never raw PII

#### 9. ğŸ“‹ **Report Assembly Agent**
- **Role**: Creates publication-ready deliverables
- **Input**: All analysis artifacts + narratives + charts
- **Output**: CLI summary + Markdown report + PDF + interactive plots
- **Report Includes**:
  - 1-page executive summary with key findings
  - Data health snapshot (missing values, quality flags)
  - KPI tables sorted by policy importance
  - Interactive time series and geographic visualizations
  - Statistical test results with caveats
  - Actionable recommendations with confidence scores

### **Infrastructure Agents**

#### 10. ğŸ§  **Memory Agent**
- **Role**: Learns from past runs to speed up future analysis
- **Input**: Run artifacts + transform decisions + schemas
- **Output**: Reusable transform patterns + schema mappings
- **Smart Features**:
  - Dataset fingerprinting (schema + sample hash)
  - Transform rule reuse across similar datasets
  - LLM response caching to avoid repeated token usage
  - Schema similarity matching for new datasets

#### 11. ğŸ‘ï¸ **Observability Agent**
- **Role**: Full pipeline traceability and debugging
- **Input**: All agent execution events
- **Output**: LangSmith traces + structured logs + audit trail
- **Tracking Features**:
  - Every transform logged with justification
  - LLM prompt/response tracing (redacted for privacy)
  - Performance metrics and bottleneck identification
  - Reproducible run snapshots

---

## ğŸ“Š Sample Output

### CLI Executive Summary
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ RTGS Analysis: Hyderabad Vehicle Registrations 2023                 â•‘
â•‘ RunID: rtgs-vehicles-20250905-001 | Confidence: HIGH âœ…              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“ˆ KEY FINDINGS:                                                     â•‘
â•‘ â€¢ Vehicle registrations +6.2% YoY (124K â†’ 132K vehicles)            â•‘
â•‘ â€¢ Peripheral mandals 40% below city average (intervention needed)   â•‘
â•‘ â€¢ Electric vehicle adoption accelerating (+180% in Q4 2023)         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“Š TOP KPIS:          Value    â”‚ Trend â”‚ Confidence                  â•‘
â•‘ â€¢ Total Registrations  132K     â”‚  â†— +6% â”‚ HIGH                     â•‘
â•‘ â€¢ Per-Capita Rate      8.3/1K   â”‚  â†— +3% â”‚ MEDIUM                   â•‘
â•‘ â€¢ Electric Vehicle %   12.4%    â”‚ â†— +180%â”‚ HIGH                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ¯ TOP RECOMMENDATIONS:                                              â•‘
â•‘ 1. Deploy mobile registration units in low-performing mandals       â•‘
â•‘ 2. Expand EV charging infrastructure to sustain growth              â•‘
â•‘ 3. Investigate 40% urban-rural registration gap                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“ Full Report: artifacts/reports/rtgs-vehicles-20250905-001/       â•‘
â•‘ ğŸ” Trace: https://smith.langchain.com/run/abc123                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Interactive Time Series (HTML Export)
```
Month    Registrations  Trend   EV %    Per-Capita
Jan 2023    10,245       â†—      8.2%     7.8/1K
Feb 2023    10,891       â†—      9.1%     8.1/1K  
Mar 2023    11,234       â†—     10.5%     8.3/1K
...
Dec 2023    12,789       â†—     18.7%     9.2/1K

ğŸ“Š Interactive charts available at: artifacts/plots/rtgs-vehicles-20250905-001/
```

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.9+
- 8GB+ RAM (16GB recommended for large datasets)
- API Keys: OpenAI/Anthropic (for LLM agents), LangSmith (for observability)

### 1. Clone Repository
```bash
git clone https://github.com/your-org/rtgs-ai-analyst
cd rtgs-ai-analyst
```

### 2. Install Dependencies
```bash
# Create virtual environment
python -m venv rtgs-env
source rtgs-env/bin/activate  # On Windows: rtgs-env\Scripts\activate

# Install packages
pip install -r requirements.txt
```

### 3. Configure Environment
```bash
# Copy sample config
cp config/config_sample.yaml config/config.yaml

# Set API keys
export OPENAI_API_KEY="your-openai-key"
export LANGSMITH_API_KEY="your-langsmith-key"  
export LANGSMITH_PROJECT="rtgs-analysis"

# Or create .env file
echo "OPENAI_API_KEY=your-key" >> .env
echo "LANGSMITH_API_KEY=your-key" >> .env
```

### 4. Verify Setup
```bash
# Test with sample data
python main.py run --source "examples/sample_transport_data.csv" --preview

# Should output schema inference and transforms preview
```

---

## ğŸ® Usage Guide

### Basic Commands

#### **Full Analysis**
```bash
python main.py run \
  --source "path/to/your/dataset.csv" \
  --domain-hint transport \
  --scope "district=Hyderabad,year=2023" \
  --auto-approve
```

#### **Preview Mode** (See transforms before applying)
```bash
python main.py run \
  --source "data/health_indicators.xlsx" \
  --domain-hint health \
  --preview
```

#### **Dry Run** (Schema inference only)
```bash
python main.py run \
  --source "data/education_survey.csv" \
  --dry-run
```

### Advanced Options

#### **Custom Sampling**
```bash
python main.py run \
  --source "large_dataset.csv" \
  --sample-rows 1000 \
  --mode run
```

#### **Custom Output Directory**
```bash
python main.py run \
  --source "data.csv" \
  --output-dir "artifacts/my_analysis" \
  --report-format pdf
```

#### **Scope Filtering** 
```bash
# Geographic scope
python main.py run --source "state_data.csv" --scope "district=Warangal,mandal=Hanamkonda"

# Temporal scope  
python main.py run --source "monthly_data.csv" --scope "year=2023,quarter=Q4"

# Multiple filters
python main.py run --source "data.csv" --scope "district=Hyderabad,year=2023,category=urban"
```

### Domain Hints (Optimizes analysis for specific sectors)

- `transport`: Vehicle registrations, traffic data, road infrastructure
- `health`: Disease surveillance, hospital data, vaccination records
- `education`: School enrollment, dropout rates, exam results  
- `economics`: GDP, employment, budget allocation
- `agriculture`: Crop yields, farmer data, land records

---

## ğŸ“ Project Structure

```
rtgs-ai-analyst/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ­ orchestrator/           # LangGraph pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ flow_controller.py     # Main agent flow DAG
â”‚   â”‚   â””â”€â”€ agent_router.py        # Output routing between agents
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¤– agents/                 # Individual agent implementations  
â”‚   â”‚   â”œâ”€â”€ ingestion_agent.py     # Data fetching & sampling
â”‚   â”‚   â”œâ”€â”€ schema_agent.py        # Type inference & canonicalization
â”‚   â”‚   â”œâ”€â”€ standardization_agent.py # Column naming & formatting
â”‚   â”‚   â”œâ”€â”€ cleaning_agent.py      # Missing data & outlier handling
â”‚   â”‚   â”œâ”€â”€ transformation_agent.py # Feature engineering
â”‚   â”‚   â”œâ”€â”€ validation_agent.py    # Quality gates & confidence scoring
â”‚   â”‚   â”œâ”€â”€ analysis_agent.py      # Statistical analysis & KPIs
â”‚   â”‚   â”œâ”€â”€ insight_agent.py       # LLM-powered narrative generation
â”‚   â”‚   â”œâ”€â”€ report_agent.py        # Report assembly & visualization
â”‚   â”‚   â”œâ”€â”€ memory_agent.py        # Learning & caching
â”‚   â”‚   â””â”€â”€ observability_agent.py # Tracing & logging
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ”§ utils/                  # Helper functions
â”‚       â”œâ”€â”€ data_utils.py          # Pandas/Polars helpers
â”‚       â”œâ”€â”€ plot_utils.py          # Plotly chart generation
â”‚       â”œâ”€â”€ config_manager.py      # Configuration handling
â”‚       â””â”€â”€ llm_utils.py           # LLM prompt templates & caching
â”‚
â”œâ”€â”€ ğŸ“Š artifacts/                  # Generated analysis outputs
â”‚   â”œâ”€â”€ docs/                                      
â”‚   â”œâ”€â”€ reports/                   # Markdown & PDF reports
â”‚   â””â”€â”€ logs/                      # Transform logs & run manifests
â”‚
â”œâ”€â”€ ğŸ”§ config.yaml                   # Configuration files
â”‚
â”‚
â”œâ”€â”€ ğŸ“– examples/                  # Sample datasets & demos
â”‚   â”œâ”€â”€ transport_demo/           # Vehicle registration sample
â”‚   â”œâ”€â”€ health_demo/              # Disease surveillance sample
â”‚   â””â”€â”€ education_demo/           # School enrollment sample
â”‚
â”œâ”€â”€ ğŸ“‹ main.py                    # CLI entry point
â”œâ”€â”€ ğŸ requirements.txt           # Python dependencies
â”œâ”€â”€ âš™ï¸ .env.sample               # Environment variables template
â””â”€â”€ ğŸ“– README.md                 # This file
```

---

## ğŸ”§ Configuration

### **Main Config** (`config/config.yaml`)

```yaml
# Data Quality Thresholds (all configurable)
data_quality:
  sample_rows_default: 500
  drop_column_threshold: 0.95        # Drop if >95% null
  median_impute_threshold: 0.05      # Median impute if <5% null  
  group_impute_threshold: 0.20       # Group impute if <20% null
  high_missingness_threshold: 0.30   # Flag column as low-quality
  max_auto_drop_rows_percent: 0.01   # Require approval if >1% rows dropped
  outlier_iqr_multiplier: 1.5        # IQR outlier detection sensitivity

# Statistical Analysis
analysis:
  significance_alpha: 0.05           # P-value threshold
  effect_size_thresholds:
    small: 0.2                       # Cohen's d thresholds
    medium: 0.5
    large: 0.8
  correlation_threshold: 0.6         # Highlight correlations above this

# LLM Settings  
llm:
  model: "gpt-4o-mini"              # Fast model for most tasks
  model_advanced: "gpt-4o"          # Advanced model for complex insights
  max_tokens: 1000                   # Token limit per call
  cache_responses: true              # Cache by prompt fingerprint
  pii_redaction: true               # Never send raw PII to external LLMs

# Memory & Caching
memory:
  enable_schema_reuse: true         # Reuse transforms across similar datasets
  similarity_threshold: 0.7        # Schema similarity for reuse suggestions
  max_memory_entries: 1000         # Limit stored transform patterns

# Observability
observability:
  langsmith_enabled: true          # Send traces to LangSmith
  local_logs: true                 # Always keep local JSONL logs
  log_level: "INFO"               # DEBUG, INFO, WARNING, ERROR
```

### **Domain-Specific Rules** (`config/domain_mappings/`)

```yaml
# transport.yaml
canonical_columns:
  - pattern: ["vehicle.*reg.*", "veh.*reg.*", "registration.*"]
    canonical: "vehicle_registration_date"
    type: "datetime"
  - pattern: ["owner.*name", "proprietor", "holder"]  
    canonical: "owner_name"
    type: "text"
    pii: true

kpi_priorities:
  - "total_registrations"
  - "registrations_per_capita" 
  - "electric_vehicle_percentage"
  - "average_vehicle_age"

feature_templates:
  - name: "registrations_per_capita"
    formula: "total_registrations / population * 1000"
    requires: ["population"]
```

---

## ğŸ“Š Understanding the Output

### **Artifacts Directory Structure**
After each run, RTGS creates a timestamped folder with all outputs:

```
artifacts/reports/rtgs-vehicles-20250905-001/
â”œâ”€â”€ ğŸ“‹ run_manifest.json           # Run metadata & parameters
â”œâ”€â”€ ğŸ“ report.md                   # Full markdown report  
â”œâ”€â”€ ğŸ“„ report.pdf                  # PDF version (if requested)
â”œâ”€â”€ ğŸ“Š plots/                      # Interactive visualizations
â”‚   â”œâ”€â”€ time_series.html           # Plotly time series charts
â”‚   â”œâ”€â”€ spatial_analysis.html      # Geographic heatmaps  
â”‚   â”œâ”€â”€ correlation_matrix.html    # Interactive correlation plot
â”‚   â””â”€â”€ kpi_dashboard.html         # Executive KPI dashboard
â”œâ”€â”€ ğŸ“ data/                       # Processed datasets
â”‚   â”œâ”€â”€ raw_sample.csv             # Original data sample
â”‚   â”œâ”€â”€ standardized.csv           # Post-standardization  
â”‚   â”œâ”€â”€ cleaned.parquet            # Post-cleaning (Parquet for efficiency)
â”‚   â””â”€â”€ transformed.parquet        # Analysis-ready final dataset
â””â”€â”€ ğŸ“‹ logs/                       # Audit trail
    â”œâ”€â”€ transform_log.jsonl        # Every transform with justification
    â”œâ”€â”€ validation_report.json     # Quality gates & confidence scores
    â””â”€â”€ agent_trace.jsonl          # Agent execution timeline
```

### **Key Files Explained**

#### **ğŸ“‹ run_manifest.json** - Run Metadata
```json
{
  "run_id": "rtgs-vehicles-20250905-001",
  "dataset_name": "hyderabad_vehicle_registrations",
  "source_url": "data/vehicles_2023.csv", 
  "scope": "district=Hyderabad,year=2023",
  "row_count_raw": 124234,
  "sample_rows_count": 500,
  "schema_hash": "abc123def456",
  "timestamp_utc": "2025-09-05T12:00:00Z",
  "confidence_overall": "HIGH",
  "agent_versions": {
    "ingestion": "v1.2",
    "cleaning": "v1.1", 
    "analysis": "v1.3"
  },
  "artifacts_paths": {
    "raw": "data/raw_sample.csv",
    "cleaned": "data/cleaned.parquet", 
    "report": "report.md",
    "plots": "plots/"
  },
  "notes": "High-quality dataset with minimal missing values"
}
```

#### **ğŸ“‹ transform_log.jsonl** - Audit Trail
```json
{"timestamp": "2025-09-05T12:01:15Z", "agent": "cleaning", "action": "median_impute", "column": "vehicle_age", "rows_affected": 1247, "rule_id": "num_median_impute_v1", "rationale": "null_frac=0.03 below threshold 0.05", "confidence": "high", "preview_before": "[null, null, 5]", "preview_after": "[8, 8, 5]"}
{"timestamp": "2025-09-05T12:01:22Z", "agent": "transformation", "action": "derive_feature", "column": "registrations_per_capita", "rows_affected": 124234, "rule_id": "per_capita_v1", "formula": "total_registrations / population * 1000", "confidence": "high"}
{"timestamp": "2025-09-05T12:02:45Z", "agent": "analysis", "action": "hypothesis_test", "test": "t_test", "groups": ["urban", "rural"], "p_value": 0.001, "effect_size": 0.8, "conclusion": "significant_difference"}
```

#### **ğŸ“‹ validation_report.json** - Quality Assessment
```json
{
  "gate_results": [
    {"gate": "completeness_check", "status": "PASS", "details": "All key columns <20% missing"},
    {"gate": "type_consistency", "status": "PASS", "details": "No type conflicts detected"},
    {"gate": "outlier_check", "status": "WARNING", "details": "12 extreme outliers flagged in vehicle_price"}
  ],
  "data_confidence_score": 0.85,
  "key_metrics": {
    "pct_columns_changed": 15.2,
    "pct_rows_changed": 8.7, 
    "num_rules_applied": 23
  },
  "recommended_actions": [
    "Review flagged outliers in vehicle_price column",
    "Consider additional validation for owner_age field"
  ]
}
```

---

## ğŸ§ª Testing

### **Run Test Suite**
```bash
# All tests
python -m pytest tests/ -v

# Unit tests only  
python -m pytest tests/unit/ -v

# Integration tests (requires sample data)
python -m pytest tests/integration/ -v

# Test specific agent
python -m pytest tests/unit/test_cleaning_agent.py -v
```

### **Test Coverage**
```bash
pip install pytest-cov
python -m pytest tests/ --cov=src --cov-report=html
open htmlcov/index.html  # View coverage report
```

### **Synthetic Test Data**
RTGS includes synthetic datasets for testing each domain:

```bash
# Test transport analysis
python main.py run --source "tests/fixtures/synthetic_transport.csv" --domain-hint transport

# Test health analysis  
python main.py run --source "tests/fixtures/synthetic_health.csv" --domain-hint health

# Test education analysis
python main.py run --source "tests/fixtures/synthetic_education.csv" --domain-hint education
```

---

## ğŸ” Troubleshooting

### **Common Issues & Solutions**

#### **ğŸš¨ Error: "LangSmith API key not found"**
```bash
# Solution: Set environment variable
export LANGSMITH_API_KEY="your-key"
# Or disable LangSmith in config
echo "observability:\n  langsmith_enabled: false" >> config/config.yaml
```

#### **ğŸš¨ Error: "Memory usage too high"**
```bash
# Solution: Reduce sample size or use streaming
python main.py run --source "large_file.csv" --sample-rows 100 --streaming
```

#### **ğŸš¨ Error: "Schema inference failed"**
```bash
# Solution: Check file encoding and format
python main.py run --source "data.csv" --encoding "utf-8" --separator ";" --dry-run
```

#### **ğŸš¨ Error: "Too many missing values"**
```bash
# Solution: Adjust thresholds or use permissive mode
python main.py run --source "messy_data.csv" --permissive --high-missingness-threshold 0.5
```

### **Debug Mode**
```bash
# Enable verbose logging
python main.py run --source "data.csv" --log-level DEBUG

# Save intermediate outputs  
python main.py run --source "data.csv" --save-intermediates

# Skip problematic agents
python main.py run --source "data.csv" --skip-agents "insight,memory"
```

### **Performance Optimization**
```bash
# For large datasets (>1M rows)
python main.py run --source "big_data.csv" --chunk-size 50000 --parallel

# Use faster LLM for development
python main.py run --source "data.csv" --llm-model "gpt-4o-mini"

# Skip expensive operations
python main.py run --source "data.csv" --skip-hypothesis-tests --skip-correlations
```

---

## ğŸš€ Advanced Features

### **ğŸ§  Semantic Q&A** (Optional)
Query your processed datasets in natural language:

```bash
# Enable semantic search
python main.py run --source "data.csv" --enable-semantic-qa

# Ask questions about your data
python main.py query --run-id "rtgs-vehicles-20250905-001" \
  --question "Which districts have the highest vehicle registration growth?"
```

### **ğŸ“Š Run Comparison**
Compare analyses across time periods or regions:

```bash
# Compare two runs
python main.py compare \
  --run1 "rtgs-vehicles-20250805-001" \
  --run2 "rtgs-vehicles-20250905-001" \
  --output "comparison_report.md"
```

### **ğŸ›ï¸ What-If Analysis** (Experimental)
Simulate policy scenarios:

```bash
# Simulate 10% budget increase impact
python main.py simulate \
  --run-id "rtgs-health-20250905-001" \
  --scenario "budget_increase=10%" \
  --metric "hospital_beds_per_capita"
```

### **ğŸ“± Interactive Dashboard** (Optional)
Launch a web interface for non-technical users:

```bash
# Start dashboard server
python dashboard.py --port 8080

# Access at http://localhost:8080
# Upload datasets, view reports, ask questions
```

---

## ğŸ† Hackathon Demo Script

### **2-Minute Demo Flow**

#### **Minute 1: Problem Setup** 
"Government analysts spend weeks cleaning messy datasets like this Telangana vehicle registration data. Watch RTGS do it in 30 seconds..."

```bash
# Live demo command
python main.py run \
  --source "demo/telangana_vehicles_messy.csv" \
  --domain-hint transport \
  --scope "district=Hyderabad,year=2023"
```

#### **Minute 2: Results Showcase**
- **CLI Summary**: "Instant executive summary with confidence scores"
- **Interactive Charts**: "Click through Plotly visualizations" 
- **Audit Trail**: "Every transform is logged and traceable"
- **Policy Recommendations**: "AI-generated insights with statistical backing"

### **Judge Q&A Prep**

**Q: "How does this compare to existing tools?"**
A: "Unlike static BI tools, RTGS adapts to any government dataset structure and provides AI-powered insights with confidence scoring and full audit trails."

**Q: "What about data privacy?"**  
A: "All PII is detected and never sent to external LLMs